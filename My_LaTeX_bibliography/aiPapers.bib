GENERAL DEEP LEARNING KNOWLEDGE

@book{Goodfellow-et-al-2016,
	title={Deep Learning},
	author={I. Goodfellow and Y. Bengio and A. Courville},
	publisher={MIT Press},
	note={\url{www.deeplearningbook.org}},
	year={2016}
}



GENERAL APPLICATIONS AND PAPERS


@article{Goodfellow2013_BOLTZMANN,
	author = {Goodfellow, Ian J. and Mirza, Mehdi and Courville, Aaron and Bengio, Yoshua},
	issn = {10495258},
	journal = {Advances in Neural Information Processing Systems},
	pages = {1--9},
	title = {{Multi-prediction deep Boltzmann machines}},
	year = {2013}
}



@article{Krizhevsky2012_IMAGENET,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey},
	doi = {10.1201/9781420010749},
	isbn = {9781420010749},
	journal = {Advances in Neural Information Processing Systems},
	number = {NIPS},
	title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
	year = {2012}
}



@article{Taigman2014_DEEPFACE,
	archivePrefix = {arXiv},
	arxivId = {1501.05703},
	author = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
	doi = {10.1109/CVPR.2014.220},
	eprint = {1501.05703},
	isbn = {9781479951178},
	issn = {10636919},
	journal = {Computer Vision Foundation},
	number = {CVPR},
	pmid = {21646680},
	title = {{DeepFace: Closing the Gap to Human-Level Performance in Face Verification}},
	year = {2014}
}





INTERESTING PROPERTIES


@techreport{CONVareDENSE_Ma2017,
	archivePrefix = {arXiv},
	arxivId = {1712.01252},
	author = {Ma, Wei and Lu, Jun},
	eprint = {1712.01252},
	number = {3},
	pages = {1--9},
	title = {{An Equivalence of Fully Connected Layer and Convolutional Layer}},
	url = {http://arxiv.org/abs/1712.01252},
	year = {2017}
}

@article{CONVareDENSE_Kleinsmith2018_medium,
	author = {Kleinsmith, Matthew},
	journal = {Medium.com},
	title = {{CNNs from different viewpoints}},
	url = {https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c},
	year = {2018},
	note = {Accessed on March 2021}
}

@article{Nawi2013_ZNORMandPREPROC,
	author = {Nawi, Nazri Mohd and Atomi, Walid Hasen and Rehman, M.Z.},
	doi = {10.1016/j.protcy.2013.12.159},
	issn = {22120173},
	journal = {Procedia Technology},
	keywords = {artificial neural networks,back propagation,gain value,gradient descent,pre-processing data},
	number = {Iceei},
	pages = {32--39},
	publisher = {Elsevier B.V.},
	title = {{The Effect of Data Pre-processing on Optimized Training of Artificial Neural Networks}},
	url = {http://dx.doi.org/10.1016/j.protcy.2013.12.159},
	volume = {11},
	year = {2013}
}



@inproceedings{Ioffe2015_BATCHNORMALIZATION,
	author = {Ioffe, Sergey and Szegedy, Christian},
	title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	year = {2015},
	publisher = {JMLR.org},
	booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
	pages = {448–456},
	numpages = {9},
	location = {Lille, France},
	series = {ICML'15}
}













RESIDUAL BLOCKS



@article{He2016_ResidualNN,
	archivePrefix = {arXiv},
	arxivId = {1512.03385},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	doi = {10.1109/CVPR.2016.90},
	eprint = {1512.03385},
	file = {:Volumes/Mac_Fra_Maxtor/PhD TO/PhD doc/Mendeley/PDFforMendeley/1512.03385_ResNN.pdf:pdf},
	isbn = {9781467388504},
	issn = {10636919},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	pages = {770--778},
	title = {{Deep residual learning for image recognition}},
	volume = {2016-Decem},
	year = {2016}
}






GRAPH NEURAL NETWORKS



@article{GNNsurvey2020,
	author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
	journal={IEEE Transactions on Neural Networks and Learning Systems}, 
	title={A Comprehensive Survey on Graph Neural Networks}, 
	year={2021},
	volume={32},
	number={1},
	pages={4-24},
	doi={10.1109/TNNLS.2020.2978386}
}


@inproceedings{graphNODEEP_Li2018, 
	title = {Deeper Insights Into Graph Convolutional Networks for Semi-Supervised Learning}, 
	volume = {32}, 
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11604},
	number = {1}, 
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence}, 
	author = {Li, Qimai and Han, Zhichao and Wu, Xiao-ming}, 
	year = {2018}, 
	month = {Apr.} 
}


@book{IntroGNN2020,
	author = {Liu, Zhiyuan and Zhou, Jie},
	booktitle = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	publisher = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
	doi = {10.2200/S00980ED1V01Y202001AIM045},
	issn = {19394616},
	keywords = {deep graph learning,deep learning,graph analysis,graph convolutional network,graph neural network,graph recurrent network,graph residual network},
	number = {2},
	pages = {1--127},
	title = {{Introduction to Graph Neural Networks}},
	volume = {14},
	year = {2020}
}


@inproceedings{DiffGCN2016,
	author = {Atwood, James and Towsley, Don},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {29},
	publisher = {Curran Associates, Inc.},
	title = {{Diffusion-Convolutional Neural Networks}},
	pages = {1993--2001},
	url = {http://papers.nips.cc/paper/6212-diffusion-convolutional-neural-networks.pdf},
	year = {2016}
}



@article{Donon2019_GraphOfNN,
	author = {Donon, Balthazar and Donnot, Benjamin and {Gu\-yon}, Isabelle and Marot, Antoine},
	doi = {10.1109/IJCNN.2019.8851855},
	isbn = {9781728119854},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	keywords = {Graph Neural Net,Graph Neural Solver,Neural Solver,Power Systems},
	number = {July},
	pages = {1--8},
	publisher = {IEEE},
	title = {{Graph Neural Solver for Power Systems}},
	volume = {2019-July},
	year = {2019}
}



@article{Donon2020_GraphOfNN,
	author = {Donon, Balthazar and Cl{\'{e}}ment, R{\'{e}}my and Donnot, Benjamin and Marot, Antoine and {Gu\-yon}, Isabelle and Schoenauer, Marc},
	doi = {10.1016/j.epsr.2020.106547},
	issn = {03787796},
	journal = {Electric Power Systems Research},
	keywords = {Artificial neural networks,Graph neural networks,Graph neural solver,Power flow,Solver},
	number = {October 2019},
	pages = {106547},
	publisher = {Elsevier},
	title = {{Neural networks for power flow: Graph neural solver}},
	url = {https://doi.org/10.1016/j.epsr.2020.106547},
	volume = {189},
	year = {2020}
}


@INPROCEEDINGS{firstGNN_Gori2005,
	author={Gori, M. and Monfardini, G. and Scarselli, F.},
	booktitle={Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.}, 
	title={A new model for learning in graph domains}, 
	year={2005},
	volume={2},
	number={},
	pages={729-734 vol. 2},
	doi={10.1109/IJCNN.2005.1555942}
}

@ARTICLE{firstGNN_Micheli2009,
	author={Micheli, Alessio},
	journal={IEEE Transactions on Neural Networks}, 
	title={Neural Network for Graphs: A Contextual Constructive Approach}, 
	year={2009},
	volume={20},
	number={3},
	pages={498-511},
	doi={10.1109/TNN.2008.2010350}
}

@ARTICLE{firstGNN_Scarselli2009,
	author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
	journal={IEEE Transactions on Neural Networks}, 
	title={The Graph Neural Network Model}, 
	year={2009},
	volume={20},
	number={1},
	pages={61-80},
	doi={10.1109/TNN.2008.2005605}
}


@INPROCEEDINGS{firstspectralGCNN_Bruna2013,
	author={Bruna, J. and Zaremba, W. and Szlam, A. and LeCun, Y.},
	booktitle={Proceedings of the International Conference on Learning Representations}, 
	title={Spectral networks and locally connected networks on graphs}, 
	year={2014}
}

@inproceedings{specGCNN_NIPS2016,
	author = {Defferrard, M. and Bresson, X. and Vandergheynst, P.},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {3844--3852},
	publisher = {Curran Associates, Inc.},
	title = {{Convolutional neural networks on graphs with fast localized spectral filtering}},
	volume = {29},
	year = {2016}
}

@INPROCEEDINGS{specGCNN_ICLR2017,
	author={Kipf, {T. N.} and Welling, M.},
	booktitle={Proceedings of the International Conference on Learning Representations}, 
	title={Semi-supervised classification with graph convolutional networks}, 
	year={2017}
}

@inproceedings{spatialGCNN_NIPS2017,
	author = {Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	title = {Inductive Representation Learning on Large Graphs},
	url = {https://proceedings.neurips.cc/paper/2017/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf},
	volume = {30},
	year = {2017}
}

@inproceedings{spatialGCNN_monti2016,
	title={Geometric deep learning on graphs and manifolds using mixture model CNNs}, 
	author={Federico Monti and Davide Boscaini and Jonathan Masci and Emanuele Rodolà and Jan Svoboda and Michael M. Bronstein},
	year={2017},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages = {5115--5124}
}


@InProceedings{spatialGCNN_niepert16,
	title = {Learning Convolutional Neural Networks for Graphs},
	author = {Niepert, Mathias and Ahmed, Mohamed and Kutzkov, Konstantin},
	booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
	pages = {2014--2023},
	year = {2016},
	volume = {48},
	series = {Proceedings of Machine Learning Research},
	address = {New York, New York, USA},
	month = {20--22 Jun},
	publisher = {PMLR},
	pdf = {http://proceedings.mlr.press/v48/niepert16.pdf},
	url = {https://proceedings.mlr.press/v48/niepert16.html},
}


@article{spatialGCNN_Gao2018,
	title={Large-Scale Learnable Graph Convolutional Networks},
	ISBN={9781450355520},
	url={http://dx.doi.org/10.1145/3219819.3219947},
	DOI={10.1145/3219819.3219947},
	journal={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	publisher={ACM},
	author={Gao, Hongyang and Wang, Zhengyang and Ji, Shuiwang},
	year={2018},
	month={Jul}
}


@InProceedings{MessagePassing_Gilmer2013,
	title = {Neural Message Passing for Quantum Chemistry},
	author = {Justin Gilmer and Samuel S. Schoenholz and Patrick F. Riley and Oriol Vinyals and George E. Dahl},
	booktitle = {Proceedings of the 34th International Conference on Machine Learning},
	pages = {1263--1272},
	year = {2017},
	editor = {Precup, Doina and Teh, Yee Whye},
	volume = {70},
	series = {Proceedings of Machine Learning Research},
	month = {06--11 Aug},
	publisher = {PMLR},
	pdf = {http://proceedings.mlr.press/v70/gilmer17a/gilmer17a.pdf},
	url = {https://proceedings.mlr.press/v70/gilmer17a.html},
}




PHYSICS INFORMED NNs


@article{Raissi18_PINN,
	title = {Hidden physics models: Machine learning of nonlinear partial differential equations},
	journal = {Journal of Computational Physics},
	volume = {357},
	pages = {125 - 141},
	year = {2018},
	issn = {0021-9991},
	doi = {https://doi.org/10.1016/j.jcp.2017.11.039},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999117309014},
	author = {Raissi, Maziar and Karniadakis, George Em},
	keywords = {Probabilistic machine learning, System identification, Bayesian modeling, Uncertainty quantification, Fractional equations, Small data},
}

@article{Raissi19_PINN,
	title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
	journal = {Journal of Computational Physics},
	volume = {378},
	pages = {686 - 707},
	year = {2019},
	issn = {0021-9991},
	doi = {https://doi.org/10.1016/j.jcp.2018.10.045},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999118307125},
	author = {Raissi, Maziar and Perdikaris, P. and Karniadakis, George, Em},
	keywords = {Data-driven scientific computing, Machine learning, Predictive modeling, Runge–Kutta methods, Nonlinear dynamics},
}






ALPHA GO


@article{Silver2016_ALPHAGO,
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and {Van Den Driessche}, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	doi = {10.1038/nature16961},
	issn = {14764687},
	journal = {Nature},
	number = {7587},
	pages = {484--489},
	pmid = {26819042},
	publisher = {Nature Publishing Group},
	title = {{Mastering the game of Go with deep neural networks and tree search}},
	url = {http://dx.doi.org/10.1038/nature16961},
	volume = {529},
	year = {2016}
}


@article{Silver2017_ALPHAGO,
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and {Van Den Driessche}, George and Graepel, Thore and Hassabis, Demis},
	doi = {10.1038/nature24270},
	issn = {14764687},
	journal = {Nature},
	number = {7676},
	pages = {354--359},
	pmid = {29052630},
	publisher = {Nature Publishing Group},
	title = {{Mastering the game of Go without human knowledge}},
	url = {http://dx.doi.org/10.1038/nature24270},
	volume = {550},
	year = {2017}
}



@article{Silver2018_ALPHAGO,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	doi = {10.1126/science.aar6404},
	issn = {10959203},
	journal = {Science},
	number = {6419},
	pages = {1140--1144},
	pmid = {30523106},
	title = {{A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play}},
	volume = {362},
	year = {2018}
}

@article{Schrittwieser2020_ALPHAGO,
	archivePrefix = {arXiv},
	arxivId = {1911.08265},
	author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
	doi = {10.1038/s41586-020-03051-4},
	eprint = {1911.08265},
	issn = {14764687},
	journal = {Nature},
	number = {7839},
	pages = {604--609},
	pmid = {33361790},
	publisher = {Springer US},
	title = {{Mastering Atari, Go, chess and shogi by planning with a learned model}},
	url = {http://dx.doi.org/10.1038/s41586-020-03051-4},
	volume = {588},
	year = {2020}
}



ALPHAFOLD


@article{Senior2019_ALPHAFOLD,
	author = {Senior, Andrew W and Evans, Richard and Jumper, John and Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin, Chongli and {\v{Z}}{\'{i}}dek, Augustin and Nelson, Alexander W R and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones, David T and Silver, David and Kavukcuoglu, Koray and Hassabis, Demis},
	doi = {10.1038/s41586-019-1923-7},
	file = {:Volumes/Mac_Fra_Maxtor/PhD TO/PhD doc/Mendeley/PDFforMendeley/ALPHAFOLD_10.1038@s41586-019-1923-7.pdf:pdf},
	number = {April},
	title = {{Improved protein structure prediction using potentials from deep learning}},
	year = {2019}
}





GPT3

@article{Brown2020_GPT3,
	archivePrefix = {arXiv},
	arxivId = {arXiv:2005.14165v4},
	author = {Brown, Tom B and Kaplan, Jared and Ryder, Nick and Henighan, Tom and Chen, Mark and Herbert-voss, Ariel and Ziegler, Daniel M and Krueger, Gretchen and Askell, Amanda and Hesse, Christopher and Mccandlish, Sam},
	eprint = {arXiv:2005.14165v4},
	title = {{Language Models are Few-Shot Learners}}
}





FRAMEWORKS


@misc{keras2015,
	title={Keras},
	author={Chollet, Fran\c{c}ois and others},
	year={2015},
	howpublished={\url{https://keras.io}},
}


@misc{tensorflow2015-whitepaper,
	title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	url={https://www.tensorflow.org/},
	note={Software available from tensorflow.org},
	author={Mart\'{i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and
	Andy~Davis and Jeffrey~Dean and	Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dandelion~Man\'{e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
	year={2015},
}


@inproceedings{torch2011,
	author={Collobert, Ronan and Kavukcuoglu, Koray and Farabet, Cl\`{e}ment},
	booktitle = {BigLearn, NIPS Workshop, number EPFL-CONF-192376},
	pages = {},
	title={Torch7: AMatlab-like environ- ment for machine learning},
	year = {2011}
}


@inproceedings{theano2012,
	author={Bastien, Fr\`{e}d\`{e}ric and Lamblin, Pascal and Pascanu, Razvan and Bergstra, James and Goodfellow, Ian and Bergeron, Arnaud and Bouchard, Nicolas and Warde-Farley, David and Bengio, Yoshua},
	booktitle = {Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop},
	pages = {},
	title={Theano: new features and speed improvements},
	year = {2012}
}


@misc{MatlabDLtoolbox,
	title={Deep Learning Toolbox Reference},
	author={Mathworks},
	url={https://it.mathworks.com/help/deeplearning/}	
}

HISTORY OF NEURAL NETWORKS


@article{McCulloch1943_NEURON,
	author = {McCulloch, Warren S. and Pitts, Walter H.},
	journal = {Bulletin of Mathematical Biophysics},
	pages = {115--133},
	title = {{A Logical Calculus of the Ideas Immanent in Nervous Activity}},
	volume = {5},
	year = {1943}
}


@book{Hebb1949_LEARNING,
	address = {New York},
	author = {Hebb, Donald O.},
	publisher = {Wiley},
	title = {{The Organization of Behavior}},
	year = {1949}
}


@article{Rosenblatt1958_PERCEPTRON,
	author = {Rosenblatt, F.},
	file = {:Volumes/Mac_Fra_Maxtor/PhD TO/PhD doc/Mendeley/PDFforMendeley/Rosenblatt1958.pdf:pdf},
	journal = {Psychological Review},
	number = {6},
	pages = {386--408},
	title = {{The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain}},
	volume = {65},
	year = {1958}
}

@book{Rosenblatt1962,
	address = {Washington},
	author = {Rosenblatt, Frank},
	pages = {616},
	publisher = {Spartan Books},
	title = {{Principles of Neurodynamics. Perceptrons and the Theory of Brain Mechanism}},
	year = {1962}
}

@article{Widrow1960_ADALINE,
	author = {Widrow, Bernard and Hoff, Marcian E.},
	journal = {1960 IRE WESCON Convention Record},
	pages = {96--104},
	title = {{Adaptive switching circuits}},
	volume = {4},
	year = {1960}
}

@article{Loiseau2019_NNORIGINS,
	author = {Loiseau, Jean-Christophe B.},
	journal = {Towardsdatascience.com},
	title = {{Rosenblatt's Perceptron, the First Modern Neural Network}},
	url = {https://towardsdatascience.com/rosenblatts-perceptron-the-very-first-neural-network-37a3ec09038a},
	year = {2019},
	note = {Accessed on March 2021}
}

@book{Minsky1969,
	author = {Minsky, Marvin and Papert, Seymour A.},
	isbn = {9780262130431},
	pages = {258},
	publisher = {MIT press},
	title = {{Perceptrons}},
	year = {1969}
}


@book{Rumelhart1986_CONNECTIONISM,
	author = {Rumelhart, David E. and McClelland, James L. and Group, PDP Research},
	publisher = {MIT press},
	title = {{Parallel Distributed Processing: Explorations in the Microstructure of Cognition}},
	year = {1986}
}

@article{Rumelhart1986_BACKPROP_Nature,
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	doi = {10.1038/323533a0},
	file = {:Volumes/Mac_Fra_Maxtor/PhD TO/PhD doc/Mendeley/PDFforMendeley/Rumelhart1986_BACKPROP_Nature.pdf:pdf},
	issn = {0028-0836},
	journal = {Nature},
	month = {oct},
	number = {6088},
	pages = {533--536},
	title = {{Learning representations by back-propagating errors}},
	url = {http://www.nature.com/articles/323533a0},
	volume = {323},
	year = {1986}
}


@article{Cybenko1989_UNIVAPPROX,
	author = {Cybenko, G.},
	doi = {10.1007/BF02551274},
	journal = {Mathematics of Control Signals and Systems},
	keywords = {approximation,completeness,neural networks},
	pages = {303--314},
	title = {{Approximation by superpositions of a Sigmoidal Function}},
	volume = {2},
	year = {1989}
}

@article{Hornik1989_UNIVAPPROX,
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	doi = {10.1016/0893-6080(89)90020-8},
	issn = {08936080},
	journal = {Neural Networks},
	keywords = {Back-propagation networks,Feedforward networks,Mapping networks,Network representation capability,Sigma-Pi networks,Squashing functions,Stone-Weierstrass Theorem,Universal approximation},
	number = {5},
	pages = {359--366},
	title = {{Multilayer feedforward networks are universal approximators}},
	volume = {2},
	year = {1989}
}


@article{Hornik1990_UNIVAPPROX,
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	doi = {10.1016/0893-6080(90)90005-6},
	issn = {08936080},
	journal = {Neural Networks},
	keywords = {Approximation,Derivatives,Feedforward networks,Sobolev space},
	number = {5},
	pages = {551--560},
	title = {{Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks}},
	volume = {3},
	year = {1990}
}

@article{Hornik1991_UNIVAPPROX,
	author = {Hornik, Kurt},
	doi = {10.1016/0893-6080(91)90009-T},
	issn = {08936080},
	journal = {Neural Networks},
	keywords = {Activation function,Input environment measure,Lp($\mu$) approximation,Multilayer feedforward networks,Smooth approximation,Sobolev spaces,Uniform approximation,Universal approximation capabilities},
	number = {2},
	pages = {251--257},
	title = {{Approximation capabilities of multilayer feedforward networks}},
	volume = {4},
	year = {1991}
}


@article{Leshno1993_UNIVAPPROX,
	author = {Leshno, Moshe and Lin, Vladimir Ya. and Pinkus, Allan and Schocken, Shimon},
	doi = {10.1016/S0893-6080(05)80131-5},
	issn = {08936080},
	journal = {Neural Networks},
	keywords = {--multilayer feedforward networks,1,activation functions,approximation,b a c k,capabilities,g r o u,is a pro-,lp,n d,of a neural network,role of threshold,t,the basic building block,universal approximation},
	month = {jan},
	number = {6},
	pages = {861--867},
	title = {{Multilayer feedforward networks with a nonpolynomial activation function can approximate any function}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608005801315},
	volume = {6},
	year = {1993}
}


@article{Bengio1994_GRADIENTDESC_DIFF,
	author = {Bengio, Y. and Simard, P. and Frasconi, P.},
	doi = {10.1109/72.279181},
	issn = {1045-9227},
	journal = {IEEE Transactions on Neural Networks},
	keywords = {Long-term neurodevelopment,Monochorionic twins,Twin-to-twin transfusion syndrome},
	month = {mar},
	number = {2},
	pages = {157--166},
	title = {{Learning long-term dependencies with gradient descent is difficult}},
	url = {https://ieeexplore.ieee.org/document/279181/},
	volume = {5},
	year = {1994}
}


@incollection{McClelland1995_CONNECTIONISM,
	author = {McClelland, James L. and Rumelhart, David E. and Hinton, Geoffrey},
	booktitle = {Computation \& intelligence: collected readings},
	pages = {305--341},
	title = {{The appeal of parallel distributed processing}},
	year = {1995}
}


@article{Pinkus1999_UNIVAPPROX_SURVEY,
	author = {Pinkus, Allan},
	doi = {10.1017/S0962492900002919},
	issn = {14740508},
	journal = {Acta Numerica},
	number = {November 2008},
	pages = {143--195},
	title = {{Approximation theory of the MLP model in neural networks}},
	volume = {8},
	year = {1999}
}

@article{Maiorov2000_UNIVAPPROXhunitslowerbound,
	author = {Maiorov, {V. E.} and Meir, R.},
	doi = {10.1023/A:1018993908478},
	issn = {10197168},
	journal = {Advances in Computational Mathematics},
	keywords = {Lower bounds,Neural networks,Stochastic approximation,Upper bounds},
	number = {1},
	pages = {79--103},
	title = {{On the near optimality of the stochastic approximation of smooth functions by neural networks}},
	volume = {13},
	year = {2000}
}


@article{Hinton2006_FASTLEARNING,
	author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
	doi = {10.1162/neco.2006.18.7.1527},
	isbn = {0899-7667},
	issn = {0899-7667},
	journal = {Neural computation},
	month = {jul},
	number = {7},
	pages = {1527--54},
	pmid = {16764513},
	title = {{A fast learning algorithm for deep belief nets.}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/16764513},
	volume = {18},
	year = {2006}
}

@article{Ranzato2006,
	author = {Ranzato, Marc'Aurelio and Poultney, Christopher and Chopra, Sumit and Lecun, Yann},
	journal = {Advances in neural information processing systems},
	pages = {1137--1144},
	title = {{Efficient learning of sparse representations with an energy-based model}},
	year = {2006}
}


Sonoda2017 non dimostra per primo (già fatto da Leshno 1993), ma dice di sfruttare la cosa per la costruzione della funzione...
@article{Sonoda2017_exploitUNIVAPPROX,
	archivePrefix = {arXiv},
	arxivId = {1505.03654},
	author = {Sonoda, Sho and Murata, Noboru},
	doi = {10.1016/j.acha.2015.12.005},
	eprint = {1505.03654},
	issn = {1096603X},
	journal = {Applied and Computational Harmonic Analysis},
	keywords = {Admissibility condition,Backprojection filter,Bounded extension to L2,Integral representation,Lizorkin distribution,Neural network,Radon transform,Rectified linear unit (ReLU),Ridgelet transform,Universal approximation},
	number = {2},
	pages = {233--268},
	publisher = {Elsevier Inc.},
	title = {{Neural network with unbounded activation functions is universal approximator}},
	url = {http://dx.doi.org/10.1016/j.acha.2015.12.005},
	volume = {43},
	year = {2015}
}


HISTORY OF AI


@article{DeepBlue2002,
	author = {Campbell, Murray and Hoane, A. Joseph and Hsu, Feng Hsiung},
	doi = {10.1016/S0004-3702(01)00129-1},
	issn = {00043702},
	journal = {Artificial Intelligence},
	keywords = {Computer chess,Evaluation function,Game tree search,Parallel search,Search extensions,Selective search},
	number = {1-2},
	pages = {57--83},
	title = {Deep Blue},
	volume = {134},
	year = {2002}
}



ACTIVATION FUNCTIONS

@article{SURVEYFACTIVATIONS_Apicella2020,
	archivePrefix = {arXiv},
	arxivId = {2005.00817},
	author = {Apicella, Andrea and Donnarumma, Francesco and Isgr{\`{o}}, Francesco and Prevete, Roberto},
	eprint = {2005.00817},
	issn = {23318422},
	journal = {arXiv},
	keywords = {Activation functions,Learnable activation functions,Machine learning,Neural networks,Trainable activation functions},
	title = {{A survey on modern trainable activation functions}},
	year = {2020}
}

@techreport{SIGMOID_Cybenko1988,
	author = {Cybenko, G.},
	institution = {Department of Computer Science, Tufts University},
	title = {{Continuous Valued Neural Networks with Two Hidden Layers are Sufficient}},
	year = {1988}
}


@article{TANH_Chen1990,
	author = {Chen, F.-C.},
	doi = {10.1109/37.55123},
	isbn = {1708190104},
	issn = {0272-1708},
	journal = {IEEE Control Systems Magazine},
	month = {apr},
	number = {3},
	pages = {44--48},
	title = {{Back-propagation neural networks for nonlinear self-tuning adaptive control}},
	url = {http://ieeexplore.ieee.org/document/55123/},
	volume = {10},
	year = {1990}
}


@article{SOFTPLUS_Dugas2000,
	author = {Dugas, Charles and Bengio, Yoshua and B{\'{e}}lisle, Fran{\c{c}}ois and Nadeau, Claude and Garcia, Ren{\'{e}}},
	isbn = {0262122413},
	issn = {10495258},
	journal = {Advances in Neural Information Processing Systems},
	title = {{Incorporating second-order functional knowledge for better option pricing}},
	year = {2000}
}

@inproceedings{RELU_Nair2010,
	author = {Nair, Vinod and Hinton, Geoffrey E.},
	booktitle = {Proceedings of the 27th international conference on machine learning (ICML-10)},
	pages = {807--814},
	title = {{Rectified Linear Units Improve Restricted Boltzmann Machines}},
	year = {2010}
}

@InProceedings{RELU_Glorot2011, 
	title = {Deep Sparse Rectifier Neural Networks}, 
	author = {Xavier Glorot and Antoine Bordes and Yoshua Bengio}, 
	booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics}, 
	pages = {315--323}, 
	year = {2011}, 
	editor = {Geoffrey Gordon and David Dunson and Miroslav Dudík}, volume = {15}, 
	series = {Proceedings of Machine Learning Research}, 
	address = {Fort Lauderdale, FL, USA}, 
	month = {11--13 Apr}, 
	publisher = {JMLR Workshop and Conference Proceedings}, 
	pdf = {http://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf}, 
	url = {http://proceedings.mlr.press/v15/glorot11a.html}
}


@inproceedings{ELU_Clevert2016,
	author = {Djork{-}Arn{\'{e}} Clevert and
	Thomas Unterthiner and
	Sepp Hochreiter},
	editor = {Yoshua Bengio and
	Yann LeCun},
	title = {Fast and Accurate Deep Network Learning by Exponential Linear Units
	(ELUs)},
	booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
	San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
	year = {2016},
	url = {http://arxiv.org/abs/1511.07289},
	timestamp = {Sat, 23 Jan 2021 01:12:05 +0100},
	biburl = {https://dblp.org/rec/journals/corr/ClevertUH15.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{SWISH_Elfwing2018,
	archivePrefix = {arXiv},
	arxivId = {1702.03118},
	author = {Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
	doi = {10.1016/j.neunet.2017.12.012},
	eprint = {1702.03118},
	issn = {18792782},
	journal = {Neural Networks},
	keywords = {Atari 2600,Deep learning,Function approximation,Reinforcement learning,Sigmoid-weighted linear unit,Tetris},
	pages = {3--11},
	pmid = {29395652},
	publisher = {Elsevier Ltd},
	title = {{Sigmoid-weighted linear units for neural network function approximation in reinforcement learning}},
	url = {https://doi.org/10.1016/j.neunet.2017.12.012},
	volume = {107},
	year = {2018}
}


@inproceedings{SWISHparametric_Ramachandran2018,
	author = {Prajit Ramachandran and
	Barret Zoph and
	Quoc V. Le},
	title = {Searching for Activation Functions},
	booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
	Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings},
	publisher = {OpenReview.net},
	year = {2018},
	url = {https://openreview.net/forum?id=Hkuq2EkPf},
	timestamp = {Thu, 04 Apr 2019 13:20:09 +0200},
	biburl = {https://dblp.org/rec/conf/iclr/RamachandranZL18.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}



OPTIMIZERS

@article{Polyak1964_MOMENTUMtoSpeedUp,
	author = {Polyak, B. T.},
	doi = {10.1016/0041-5553(64)90137-5},
	issn = {00415553},
	journal = {USSR Computational Mathematics and Mathematical Physics},
	number = {5},
	pages = {1--17},
	title = {{Some methods of speeding up the convergence of iteration methods}},
	volume = {4},
	year = {1964}
}


@article{Qian1999_MOMENTUM,
	author = {Qian, Ning},
	doi = {10.1016/S0893-6080(98)00116-6},
	isbn = {1212543521},
	issn = {08936080},
	journal = {Neural Networks},
	keywords = {Critical damping,Damped harmonic oscillator,Gradient descent learning algorithm,Learning rate,Momentum,Speed of convergence},
	number = {1},
	pages = {145--151},
	title = {{On the momentum term in gradient descent learning algorithms}},
	volume = {12},
	year = {1999}
}



@misc{stanfordVisRes2020,
	author={Li, Fei-Fei and Ranjay, Krishna and Danfei, Xu and }, 
	title={CS231n: Convolutional Neural Networks for Visual Recognition}, howpublished={Stanford University Course: \url{https://cs231n.github.io/neural-networks-3/}},
	year={2020}, 
	note={Accessed on March 2021}
}



@article{Kingma2015_ADAM,
	archivePrefix = {arXiv},
	arxivId = {1412.6980},
	author = {Kingma, Diederik P. and Ba, Jimmy Lei},
	eprint = {1412.6980},
	journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
	pages = {1--15},
	title = {{Adam: A method for stochastic optimization}},
	year = {2015}
}





INITIALIZERS


@article{Glorot2010_GLOROTunifANDnormal,
	author = {Glorot, Xavier and Bengio, Yoshua},
	issn = {15324435},
	journal = {Journal of Machine Learning Research},
	pages = {249--256},
	title = {{Understanding the difficulty of training deep feedforward neural networks}},
	volume = {9},
	year = {2010}
}






UNIVAPPROX - ARBITRARY DEPTH

@inproceedings{Lu2017NIPS_UNIVAPPROXdepth,
	author = {Lu, Zhou and Pu, Hongming and Wang, Feicheng and Hu, Zhiqiang and Wang, Liwei},
	booktitle = {Advances in Neural Information Processing Systems 30},
	title = {{The expressive power of neural networks: A view from the width}},
	year = {2017}
}


@inproceedings{
	Johnson2019_UNIVAPPROXdepth,
	title={Deep, Skinny Neural Networks are not Universal Approximators},
	author={Jesse Johnson},
	booktitle={International Conference on Learning Representations},
	year={2019},
	url={https://openreview.net/forum?id=ryGgSsAcFQ},
}

@InProceedings{Kidger2020_UNIVAPPROXdepth, 
	title = {{Universal Approximation with Deep Narrow Networks}}, 
	author = {Kidger, Patrick and Lyons, Terry}, 
	booktitle = {Proceedings of Thirty Third Conference on Learning Theory}, 
	pages = {2306--2327}, 
	year = {2020}, 
	editor = {Jacob Abernethy and Shivani Agarwal}, 
	volume = {125}, 
	series = {Proceedings of Machine Learning Research}, address = {}, 
	month = {09--12 Jul}, 
	publisher = {PMLR}, 
	pdf = {http://proceedings.mlr.press/v125/kidger20a/kidger20a.pdf}, 
	url = {http://proceedings.mlr.press/v125/kidger20a.html}
}

@inproceedings{Park2021_UNIVAPPROXdepth,
	title={Minimum Width for Universal Approximation},
	author={Sejun Park and Chulhee Yun and Jaeho Lee and Jinwoo Shin},
	booktitle={International Conference on Learning Representations},
	year={2021},
	url={https://openreview.net/forum?id=O-XJwyoIF-k}
}



AUTOMATIC DIFFERENTIATION


@techreport{Beda1959_AUTODIFF,
	archivePrefix = {},
	arxivId = {},
	author = {Beda, L. M. and Korolev, L. N. and Sukkikh, N. V. and Frolova, T. S.},
	eprint = {},
	number = {},
	pages = {},
	title = {{Programs for automatic differentiation for the machine BESM (in Russian)}},
	url = {},
	institution = {Institute for Precise Mechanics and Computation Techniques, Academy of Science},
	type = {Technical report},
	address = {Moscow (USSR)},
	year = {1959}
}


@article{Wengert1964_AUTODIFF,
	author = {Wengert, R. E.},
	doi = {10.1145/355586.364791},
	issn = {0001-0782},
	journal = {Communications of the ACM},
	month = {aug},
	number = {8},
	pages = {463--464},
	title = {{A simple automatic derivative evaluation program}},
	url = {https://dl.acm.org/doi/10.1145/355586.364791},
	volume = {7},
	year = {1964}
}


@article{Linnainmaa1976_AUTODIFF,
	author = {Linnainmaa, Seppo},
	doi = {10.1007/BF01931367},
	issn = {0006-3835},
	journal = {BIT},
	month = {jun},
	number = {2},
	pages = {146--160},
	title = {{Taylor expansion of the accumulated rounding error}},
	url = {},
	volume = {16},
	year = {1976}
}


@inproceedings{Griewank1989_AUTODIFF,
	author = {Griewank, Andreas},
	booktitle = {IN MATHEMATICAL PROGRAMMING: RECENT DEVELOPMENTS AND APPLICATIONS},
	pages = {83--108},
	publisher = {Kluwer Academic Publishers},
	title = {{On Automatic Differentiation}},
	year = {1989}
}


@inproceedings{Hecht-Nielsen1989_AUTODIFF,
	author = {Hecht-Nielsen, Robert},
	booktitle = {International Joint Conference on Neural Networks},
	file = {:Volumes/Mac_Fra_Maxtor/PhD TO/PhD doc/Mendeley/PDFforMendeley/Autodiff_1989backproptheory.pdf:pdf},
	pages = {593--605},
	publisher = {IEEE},
	title = {{Theory of the backpropagation neural network}},
	year = {1989}
}



@article{Verma2000_AUTODIFF,
	author = {Verma, Arun},
	doi = {10.1002/pamm.200310012},
	issn = {00113891},
	journal = {Current Science},
	number = {7},
	pages = {804--807},
	title = {{An introduction to automatic differentiation}},
	volume = {78},
	year = {2000}
}


@article{GunesBaydin2018_AUTODiFFsurvey,
	archivePrefix = {arXiv},
	arxivId = {1502.05767},
	author = {{G{\"{u}}neş Baydin}, Atılım and Pearlmutter, Barak A. and {Andreyevich Radul}, Alexey and {Mark Siskind}, Jeffrey},
	eprint = {1502.05767},
	issn = {15337928},
	journal = {Journal of Machine Learning Research},
	keywords = {Backpropagation,Differentiable Programming},
	pages = {1--43},
	title = {{Automatic differentiation in machine learning: A survey}},
	volume = {18},
	year = {2018}
}


@book{EvalDerivatives2008,
	author = {Griewank, Andreas and Walther, Andrea},
	booktitle = {{Evaluating Derivatives}},
	edition = {Second},
	series = {},
	address = {},
	isbn = {9780898716597},
	doi = {10.1137/1.9780898717761},
	number = {},
	pages = {426},
	publisher = {Society for Industrial and Applied Mathematics},
	title = {{Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation}},
	volume = {},
	year = {2008}
}


EXPLAINABLE AI

@manual{LRPdemos,
	title={Explainable AI Demos},
	author={Bach et al., Sebastian.},
	note={(Accessed on August 2020)}
	url={https://lrpserver.hhi.fraunhofer.de/}
}

@article{Bach2015_LRP,
	title={On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
	author={Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
	journal={PloS one},
	volume={10},
	number={7},
	pages={e0130140},
	year={2015},
	publisher={Public Library of Science}
}


@incollection{Lundberg2017_SHAP_NIPS,
	title = {A Unified Approach to Interpreting Model Predictions},
	author = {Lundberg, Scott M and Lee, Su-In},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {4765--4774},
	year = {2017},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}
}

@article{Montavon2017_DeepTaylor,
	title={Explaining nonlinear classification decisions with deep taylor decomposition},
	author={Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
	journal={Pattern Recognition},
	volume={65},
	pages={211--222},
	year={2017},
	publisher={Elsevier}
}

@inproceedings{Sundararajan2017_IntegratedGradients,
	title={Axiomatic attribution for deep networks},
	author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	booktitle={Proceedings of the 34th International Conference on Machine Learning - Volume 70},
	pages={3319--3328},
	year={2017},
	organization={JMLR. org}
}

@inproceedings{Shrikumar2017_DeepLIFT,
	title={Learning important features through propagating activation differences},
	author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
	booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	pages={3145--3153},
	year={2017},
	organization={JMLR. org}
}

@article{Montavon2018_LRP_MethodsInterpreting,
	title={Methods for interpreting and understanding deep neural networks},
	author={Montavon, Gr{\'e}goire and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
	journal={Digital Signal Processing},
	volume={73},
	pages={1--15},
	year={2018},
	publisher={Elsevier}
}


@inproceedings{Dovsilovic2018_XAIsurvey,
	title={Explainable artificial intelligence: A survey},
	author={Dosilovic, Filip Karlo and Brcic, Mario and Hlupic, Nikica},
	booktitle={2018 41st International convention on information and communication technology, electronics and microelectronics (MIPRO)},
	pages={0210--0215},
	year={2018},
	organization={IEEE}
}


@article{Bohle2019_LRP_Alzheimer,
	title={Layer-wise relevance propagation for explaining deep neural network decisions in mri-based alzheimer’s disease classification},
	author={B{\"o}hle, Moritz and Eitel, Fabian and Weygandt, Martin and Ritter, Kerstin},
	journal={Frontiers in aging neuroscience},
	volume={11},
	pages={194},
	year={2019},
	publisher={Frontiers}
}


MACHINE LEARNING - GENERAL


@book{MLbook1997,
	author = {Mitchell, Tom M.},
	booktitle = {Machine Learning},
	isbn = {0070428077},
	number = {},
	pages = {432},
	publisher = {McGraw-Hill Science/Engineering/Math},
	title = {{Machine Learning}},
	volume = {},
	year = {1997}
}


@book{PatternRecBook2006,
	address = {Berlin, Heidelberg},
	author = {Bishop, Cristopher M.},
	booktitle = {Information Science and Statistics},
	editor = {Jordan, M. and Kleinberg, J. and Sch{\"{o}}lkpof, B.},
	isbn = {9780387310732},
	issn = {02094541},
	publisher = {Springer-Verlag},
	title = {{Pattern Recognition and Machine Learning}},
	year = {2006}
}


@book{Vapnik2000,
	author = {Vapnik, Vladimir N.},
	doi = {10.1007/978-1-4757-3264-1},
	edition = {Second},
	isbn = {978-1-4419-3160-3},
	publisher = {Springer},
	title = {{The Nature of Statistical Learning Theory}},
	year = {2000}
}


@article{Blumer1989,
	author = {Blumer, Anselm and Ehrenfeucht, A. and Haussler, David and Warmuth, Manfred K.},
	doi = {10.1145/76359.76371},
	issn = {1557735X},
	journal = {Journal of the ACM (JACM)},
	number = {4},
	pages = {929--965},
	title = {{Learnability and the Vapnik-Chervonenkis Dimension}},
	volume = {36},
	year = {1989}
}



GENERIC UQ/FLOW/PHYSICS APPLICATIONS


@article{MLforUQmultiscale,
	author = {Chan, S. and Elsheikh, A.H.},
	title = {A machine learning approach for efficient uncertainty quantification using multiscale methods},
	journal = {Journal of Computational Physics},
	volume = {354},
	pages = {493 - 511},
	year = {2018},
	issn = {0021-9991},
	doi = {https://doi.org/10.1016/j.jcp.2017.10.034},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999117307933},
	keywords = {Machine learning, Multiscale methods, Uncertainty quantification, Porous media flow, Neural networks},
}

@article{DLforUQsurrogatemodels,
	author = {Tripathy, R.K. and Bilionis, I.},
	title = {Deep UQ: Learning deep neural network surrogate models for high dimensional uncertainty quantification},
	journal = {Journal of Computational Physics},
	volume = {375},
	pages = {565 - 588},
	year = {2018},
	issn = {0021-9991},
	doi = {https://doi.org/10.1016/j.jcp.2018.08.036},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999118305655},
	keywords = {Deep Neural Networks, Dimensionality reduction, Stochastic elliptic PDE, Uncertainty quantification},
}
